{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx6JUE3rGZ1_"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "rRCQGaosGc-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to ndvi folder\n",
        "%cd drive/MyDrive/ndvi"
      ],
      "metadata": {
        "id": "xxCjpUKz1Y7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the data files in the folder into a list and print it out\n",
        "ndvi_files_list = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.csv'):\n",
        "    ndvi_files_list.append(file)\n",
        "\n",
        "print(\"List of Files in NDVI Folder:\")\n",
        "print(*ndvi_files_list, sep = \"\\n\")"
      ],
      "metadata": {
        "id": "6GanOoN6GdD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the filenames based on the year and quarter\n",
        "ndvi_files_sorted = sorted(ndvi_files_list, key=lambda x: (int(x.split('_')[1]), x.split('_')[2]))\n",
        "\n",
        "# Concatenate the dataframes\n",
        "ndvi_dfs = [pd.read_csv(filename) for filename in ndvi_files_sorted]\n",
        "ndvi_combined_df = pd.concat(ndvi_dfs, ignore_index=True)\n",
        "\n",
        "display(ndvi_combined_df)"
      ],
      "metadata": {
        "id": "xbOWOA4Nqvv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant columns\n",
        "ndvi_dropCol_df= ndvi_combined_df.drop([\"system:index\", \".geo\"], axis=1)\n",
        "display(ndvi_dropCol_df)"
      ],
      "metadata": {
        "id": "1fKOkmHEqv1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any null values in the data\n",
        "ndvi_dropCol_df.isnull()"
      ],
      "metadata": {
        "id": "w6BrGrHh0b-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the sum of null values (if any) for each column\n",
        "ndvi_dropCol_df.isnull().sum()"
      ],
      "metadata": {
        "id": "BNvl4mWRqvyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values using linear interpolation\n",
        "ndvi_dropCol_df['ndvi'] = ndvi_dropCol_df['ndvi'].interpolate(method=\"linear\")\n",
        "\n",
        "display(ndvi_dropCol_df)"
      ],
      "metadata": {
        "id": "fVuj89kiqv4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the sum of null values after missing values are filled\n",
        "ndvi_dropCol_df.isnull().sum()"
      ],
      "metadata": {
        "id": "DnyBfceWqv7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export dataframe into a csv file in Google Drive\n",
        "ndvi_dropCol_df.to_csv('NDVI_Complete.csv', index=False)"
      ],
      "metadata": {
        "id": "AszihyjXqv9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current directory\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Directory:\", current_directory)"
      ],
      "metadata": {
        "id": "uDNxYPdJeWOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to parent directory\n",
        "%cd .."
      ],
      "metadata": {
        "id": "VUYewJ_QGdHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to gnvi folder\n",
        "%cd gndvi"
      ],
      "metadata": {
        "id": "_kNGSl-7ZGj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the data files in the folder into a list and print it out\n",
        "gndvi_files_list = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.csv'):\n",
        "    gndvi_files_list.append(file)\n",
        "\n",
        "print(\"List of Files in GNDVI Folder:\")\n",
        "print(*gndvi_files_list, sep = \"\\n\")"
      ],
      "metadata": {
        "id": "CuPyAbSeZGmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the filenames based on the year and quarter\n",
        "gndvi_files_sorted = sorted(gndvi_files_list, key=lambda x: (int(x.split('_')[1]), x.split('_')[2]))\n",
        "\n",
        "# Concatenate the dataframes\n",
        "gndvi_dfs = [pd.read_csv(filename) for filename in gndvi_files_sorted]\n",
        "gndvi_combined_df = pd.concat(gndvi_dfs, ignore_index=True)\n",
        "\n",
        "display(gndvi_combined_df)"
      ],
      "metadata": {
        "id": "2YWfmHmtZGpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant columns\n",
        "gndvi_dropCol_df= gndvi_combined_df.drop([\"system:index\", \".geo\"], axis=1)\n",
        "display(gndvi_dropCol_df)"
      ],
      "metadata": {
        "id": "SjK2PzOsZGr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any null values (if any) in the data\n",
        "gndvi_dropCol_df.isnull()"
      ],
      "metadata": {
        "id": "4Azeh6QXZGuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the sum of null values (if any) for each column\n",
        "gndvi_dropCol_df.isnull().sum()"
      ],
      "metadata": {
        "id": "Zrksbs-zZGw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values using linear interpolation\n",
        "gndvi_dropCol_df['gndvi'] = gndvi_dropCol_df['gndvi'].interpolate(method=\"linear\")\n",
        "\n",
        "display(gndvi_dropCol_df)"
      ],
      "metadata": {
        "id": "wuZ_msBQZG0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the sum of null values after missing values are filled\n",
        "gndvi_dropCol_df.isnull().sum()"
      ],
      "metadata": {
        "id": "oy5xLnT0aecK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export dataframe into a csv file in Google Drive\n",
        "gndvi_dropCol_df.to_csv('GNDVI_Complete.csv', index=False)"
      ],
      "metadata": {
        "id": "ajJ-2DAraekN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current directory\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Directory:\", current_directory)"
      ],
      "metadata": {
        "id": "swB8QYDUlGsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to parent directory\n",
        "%cd .."
      ],
      "metadata": {
        "id": "Zwl2zVOkanhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to no2 folder\n",
        "%cd no2"
      ],
      "metadata": {
        "id": "OqtGTHZeHMu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the data files in the folder into a list and print it out\n",
        "no2_files_list = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.csv'):\n",
        "    no2_files_list.append(file)\n",
        "\n",
        "print(\"List of Files in NO2 Folder:\")\n",
        "print(*no2_files_list, sep = \"\\n\")"
      ],
      "metadata": {
        "id": "aRK8ZCd2GdMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the filenames based on the year and quarter\n",
        "no2_files_sorted = sorted(no2_files_list, key=lambda x: (int(x.split('_')[1]), x.split('_')[2]))\n",
        "\n",
        "# Concatenate the dataframes\n",
        "no2_dfs = [pd.read_csv(filename) for filename in no2_files_sorted]\n",
        "no2_combined_df = pd.concat(no2_dfs, ignore_index=True)\n",
        "\n",
        "display(no2_combined_df)"
      ],
      "metadata": {
        "id": "AAAXN-sKHOmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant columns\n",
        "no2_dropCol_df= no2_combined_df.drop([\"system:index\", \".geo\"], axis=1)\n",
        "display(no2_dropCol_df)"
      ],
      "metadata": {
        "id": "fZY890mlVPCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export dataframe into a csv file in Google Drive\n",
        "no2_dropCol_df.to_csv('NO2_Complete.csv', index=False)"
      ],
      "metadata": {
        "id": "htg7HnDEWA1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current directory\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Directory:\", current_directory)"
      ],
      "metadata": {
        "id": "iqkMgWVveYcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to parent directory\n",
        "%cd .."
      ],
      "metadata": {
        "id": "qfCfhNL-WSSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to soil moisture folder\n",
        "%cd soil_moisture"
      ],
      "metadata": {
        "id": "9gNYTuRObcSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the data files in the folder into a list and print it out\n",
        "soil_moisture_files_list = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.csv'):\n",
        "    soil_moisture_files_list.append(file)\n",
        "\n",
        "print(\"List of Files in Soil Moisture Folder:\")\n",
        "print(*soil_moisture_files_list, sep = \"\\n\")"
      ],
      "metadata": {
        "id": "bUDBN0Ifb_uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the filenames based on the year and quarter\n",
        "soil_moisture_files_sorted = sorted(soil_moisture_files_list, key=lambda x: (int(x.split('_')[1]), x.split('_')[2]))\n",
        "\n",
        "# Concatenate the dataframes\n",
        "soil_moisture_dfs = [pd.read_csv(filename) for filename in soil_moisture_files_sorted]\n",
        "soil_moisture_combined_df = pd.concat(soil_moisture_dfs, ignore_index=True)\n",
        "\n",
        "display(soil_moisture_combined_df)"
      ],
      "metadata": {
        "id": "-5BEGzoIcFCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant columns\n",
        "soil_moisture_dropCol_df= soil_moisture_combined_df.drop([\"system:index\", \".geo\"], axis=1)\n",
        "display(soil_moisture_dropCol_df)"
      ],
      "metadata": {
        "id": "jjlzx1WCcIPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export dataframe into a csv file in Google Drive\n",
        "soil_moisture_dropCol_df.to_csv(\"Soil_Moisture_Complete.csv\", index=False)"
      ],
      "metadata": {
        "id": "0NuaVjfocIQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current directory\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Directory:\", current_directory)"
      ],
      "metadata": {
        "id": "XD6zGzJ9eh0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to parent directory\n",
        "%cd .."
      ],
      "metadata": {
        "id": "dmuQnderdFwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to soil temperature folder\n",
        "%cd soil_temp"
      ],
      "metadata": {
        "id": "VRa44RczdJT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the data files in the folder into a list and print it out\n",
        "soil_temp_files_list = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.csv'):\n",
        "    soil_temp_files_list.append(file)\n",
        "\n",
        "print(\"List of Files in Soil Temperature Folder:\")\n",
        "print(*soil_temp_files_list, sep = \"\\n\")"
      ],
      "metadata": {
        "id": "AkEZqH5bdgj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the filenames based on the year and quarter\n",
        "soil_temp_files_sorted = sorted(soil_temp_files_list, key=lambda x: (int(x.split('_')[1]), x.split('_')[2]))\n",
        "\n",
        "# Concatenate the dataframes\n",
        "soil_temp_dfs = [pd.read_csv(filename) for filename in soil_temp_files_sorted]\n",
        "soil_temp_combined_df = pd.concat(soil_temp_dfs, ignore_index=True)\n",
        "\n",
        "display(soil_temp_combined_df)"
      ],
      "metadata": {
        "id": "pculRcOldi4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant columns\n",
        "soil_temp_dropCol_df= soil_temp_combined_df.drop([\"system:index\", \".geo\"], axis=1)\n",
        "display(soil_temp_dropCol_df)"
      ],
      "metadata": {
        "id": "vPhER7MwfkDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export dataframe into a csv file in Google Drive\n",
        "soil_temp_dropCol_df.to_csv(\"Soil_Temp_Complete.csv\", index=False)"
      ],
      "metadata": {
        "id": "2ukhjSkXfkFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}